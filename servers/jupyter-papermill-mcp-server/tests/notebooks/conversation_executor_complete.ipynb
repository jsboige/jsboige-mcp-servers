{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9face5a1",
   "metadata": {},
   "source": [
    "# üéØ EX√âCUTEUR CONVERSATION AGENTIQUE COMPL√àTE\n",
    "\n",
    "**Objectif :** Valider le pipeline argumentatif multi-agents apr√®s r√©paration\n",
    "- Chargement consolid√© de tous les composants (notebooks 0,1,2,3)\n",
    "- Lancement conversation agentique r√©elle (plusieurs minutes)\n",
    "- Trace conversationnelle compl√®te pour validation coh√©rence\n",
    "\n",
    "**Test critique :** V√©rifier que la r√©paration permet une analyse argumentative fonctionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a90796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 1: Chargement et ex√©cution du notebook 0-init (composants de base)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s: %(message)s')\n",
    "logger = logging.getLogger(\"ConversationExecutor\")\n",
    "\n",
    "logger.info(\"üöÄ D√âMARRAGE EX√âCUTEUR CONVERSATION AGENTIQUE\")\n",
    "logger.info(\"üìã √âTAPE 1: Chargement notebook 0-init (composants de base)\")\n",
    "\n",
    "# Ex√©cution du notebook 0-init pour charger tous les composants\n",
    "nb_init_path = \"MyIA.AI.Notebooks/SymbolicAI/Argument_Analysis/Argument_Analysis_Agentic-0-init.ipynb\"\n",
    "\n",
    "if not os.path.exists(nb_init_path):\n",
    "    raise FileNotFoundError(f\"Notebook 0-init non trouv√©: {nb_init_path}\")\n",
    "\n",
    "logger.info(f\"üìñ Chargement composants depuis: {nb_init_path}\")\n",
    "\n",
    "# Import des modules n√©cessaires pour l'ex√©cution\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # Charger et ex√©cuter le notebook 0-init\n",
    "    with open(nb_init_path, 'r', encoding='utf-8') as f:\n",
    "        nb_init = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Configurer l'ex√©cuteur\n",
    "    ep = ExecutePreprocessor(\n",
    "        timeout=300,  # 5 minutes max\n",
    "        kernel_name='python3'\n",
    "    )\n",
    "    \n",
    "    # Ex√©cuter dans le m√™me environnement\n",
    "    ep.preprocess(nb_init, {'metadata': {'path': os.path.dirname(nb_init_path)}})\n",
    "    \n",
    "    exec_time = time.time() - start_time\n",
    "    logger.info(f\"‚úÖ Notebook 0-init ex√©cut√© avec succ√®s en {exec_time:.2f}s\")\n",
    "    \n",
    "    # Extraire les d√©finitions vers l'environnement global\n",
    "    # Les classes et fonctions sont maintenant disponibles\n",
    "    logger.info(\"üîÑ Extraction des composants vers environnement global...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erreur chargement notebook 0-init: {e}\")\n",
    "    raise\n",
    "\n",
    "logger.info(\"‚úÖ √âTAPE 1 TERMIN√âE - Composants de base charg√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 2: Chargement agents sp√©cialis√©s (notebooks 1 et 2)\n",
    "logger.info(\"üìã √âTAPE 2: Chargement agents sp√©cialis√©s (notebooks 1 et 2)\")\n",
    "\n",
    "# Charger notebook 1-informal_agent\n",
    "nb_informal_path = \"MyIA.AI.Notebooks/SymbolicAI/Argument_Analysis/Argument_Analysis_Agentic-1-informal_agent.ipynb\"\n",
    "logger.info(f\"üìñ Chargement agent informel: {nb_informal_path}\")\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    with open(nb_informal_path, 'r', encoding='utf-8') as f:\n",
    "        nb_informal = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    ep.preprocess(nb_informal, {'metadata': {'path': os.path.dirname(nb_informal_path)}})\n",
    "    exec_time = time.time() - start_time\n",
    "    logger.info(f\"‚úÖ Agent informel charg√© en {exec_time:.2f}s\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erreur chargement agent informel: {e}\")\n",
    "    raise\n",
    "\n",
    "# Charger notebook 2-pl_agent\n",
    "nb_pl_path = \"MyIA.AI.Notebooks/SymbolicAI/Argument_Analysis/Argument_Analysis_Agentic-2-pl_agent.ipynb\"\n",
    "logger.info(f\"üìñ Chargement agent logique propositionnelle: {nb_pl_path}\")\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    with open(nb_pl_path, 'r', encoding='utf-8') as f:\n",
    "        nb_pl = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    ep.preprocess(nb_pl, {'metadata': {'path': os.path.dirname(nb_pl_path)}})\n",
    "    exec_time = time.time() - start_time\n",
    "    logger.info(f\"‚úÖ Agent PL charg√© en {exec_time:.2f}s\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erreur chargement agent PL: {e}\")\n",
    "    raise\n",
    "\n",
    "logger.info(\"‚úÖ √âTAPE 2 TERMIN√âE - Agents sp√©cialis√©s charg√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06697113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 3: Chargement orchestration et strat√©gies (notebook 3)\n",
    "logger.info(\"üìã √âTAPE 3: Chargement orchestration et strat√©gies (notebook 3)\")\n",
    "\n",
    "# Charger notebook 3-orchestration\n",
    "nb_orchestration_path = \"MyIA.AI.Notebooks/SymbolicAI/Argument_Analysis/Argument_Analysis_Agentic-3-orchestration.ipynb\"\n",
    "logger.info(f\"üìñ Chargement orchestration: {nb_orchestration_path}\")\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    with open(nb_orchestration_path, 'r', encoding='utf-8') as f:\n",
    "        nb_orchestration = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    ep.preprocess(nb_orchestration, {'metadata': {'path': os.path.dirname(nb_orchestration_path)}})\n",
    "    exec_time = time.time() - start_time\n",
    "    logger.info(f\"‚úÖ Orchestration charg√©e en {exec_time:.2f}s\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erreur chargement orchestration: {e}\")\n",
    "    raise\n",
    "\n",
    "# V√©rification des composants critiques charg√©s\n",
    "logger.info(\"üîç V√©rification composants critiques...\")\n",
    "required_components = [\n",
    "    'RhetoricalAnalysisState', 'StateManagerPlugin', \n",
    "    'SimpleTerminationStrategy', 'DelegatingSelectionStrategy',\n",
    "    'run_analysis_conversation', 'global_ai_service_instance'\n",
    "]\n",
    "\n",
    "missing = [comp for comp in required_components if comp not in globals()]\n",
    "if missing:\n",
    "    logger.error(f\"‚ùå Composants manquants: {missing}\")\n",
    "    raise NameError(f\"Composants critiques manquants: {missing}\")\n",
    "else:\n",
    "    logger.info(f\"‚úÖ Tous les composants critiques pr√©sents: {len(required_components)}\")\n",
    "\n",
    "logger.info(\"‚úÖ √âTAPE 3 TERMIN√âE - Pipeline complet charg√© et pr√™t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90677505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 4: LANCEMENT CONVERSATION AGENTIQUE R√âELLE\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "logger.info(\"üìã √âTAPE 4: LANCEMENT CONVERSATION AGENTIQUE R√âELLE\")\n",
    "logger.info(\"üéØ Test critique : Conversation multi-agents avec analyse argumentative compl√®te\")\n",
    "\n",
    "# Texte complexe pour test complet\n",
    "texte_analyse_complexe = \"\"\"\n",
    "Les √©nergies renouvelables sont absolument essentielles pour lutter contre le changement climatique. \n",
    "Certes, elles co√ªtent cher √† installer initialement, mais c'est un faux d√©bat car les co√ªts √©conomiques \n",
    "de l'inaction √† long terme seront bien plus √©lev√©s que les investissements actuels. De plus, \n",
    "les √©nergies renouvelables cr√©ent de nombreux emplois locaux durables, contrairement aux √©nergies \n",
    "fossiles import√©es qui nous rendent d√©pendants des fluctuations g√©opolitiques et des prix volatils. \n",
    "Ignorer cette transition √©nerg√©tique maintenant serait compl√®tement irresponsable envers les futures g√©n√©rations. \n",
    "Tout le monde sait que le nucl√©aire est dangereux, donc on n'a pas le choix.\n",
    "\"\"\"\n",
    "\n",
    "# Configuration pour asyncio (n√©cessaire en notebook)\n",
    "try:\n",
    "    nest_asyncio.apply()\n",
    "    logger.info(\"‚úÖ Asyncio configur√© pour notebook\")\n",
    "except:\n",
    "    logger.warning(\"‚ö†Ô∏è nest_asyncio d√©j√† appliqu√© ou non n√©cessaire\")\n",
    "\n",
    "# LANCEMENT DE LA CONVERSATION\n",
    "logger.info(\"üöÄ D√âMARRAGE CONVERSATION AGENTIQUE...\")\n",
    "logger.info(f\"üìù Texte √† analyser: {len(texte_analyse_complexe)} caract√®res\")\n",
    "logger.info(\"‚è±Ô∏è Dur√©e attendue: 2-5 minutes (analyse compl√®te multi-agents)\")\n",
    "\n",
    "conversation_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Lancer la conversation agentique asynchrone\n",
    "    result = await run_analysis_conversation(texte_analyse_complexe)\n",
    "    \n",
    "    conversation_duration = time.time() - conversation_start_time\n",
    "    logger.info(f\"‚úÖ CONVERSATION TERMIN√âE en {conversation_duration:.2f} secondes\")\n",
    "    logger.info(\"üìä Analyse des r√©sultats de conversation...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conversation_duration = time.time() - conversation_start_time\n",
    "    logger.error(f\"‚ùå ERREUR CONVERSATION apr√®s {conversation_duration:.2f}s: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "logger.info(\"‚úÖ √âTAPE 4 TERMIN√âE - Conversation agentique ex√©cut√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âTAPE 5: ANALYSE D√âTAILL√âE DES R√âSULTATS DE CONVERSATION\n",
    "logger.info(\"üìã √âTAPE 5: ANALYSE D√âTAILL√âE DES R√âSULTATS\")\n",
    "logger.info(\"üîç Validation coh√©rence conversation agentique...\")\n",
    "\n",
    "# Variables pour analyser les r√©sultats\n",
    "analysis_results = {\n",
    "    'conversation_duration': conversation_duration,\n",
    "    'agents_participated': [],\n",
    "    'belief_sets_created': 0,\n",
    "    'queries_executed': 0,\n",
    "    'final_conclusion': None,\n",
    "    'conversation_coherent': False,\n",
    "    'tweety_integration_working': False,\n",
    "    'informal_analysis_working': False\n",
    "}\n",
    "\n",
    "# V√©rifier si une instance d'√©tat local a √©t√© cr√©√©e\n",
    "try:\n",
    "    # La fonction run_analysis_conversation cr√©e une instance locale\n",
    "    # On va analyser les globals pour voir ce qui a √©t√© cr√©√©\n",
    "    logger.info(\"üîç Recherche traces de conversation dans globals()...\")\n",
    "    \n",
    "    # Analyser les variables disponibles\n",
    "    conversation_vars = [var for var in globals().keys() if 'conversation' in var.lower() or 'state' in var.lower()]\n",
    "    logger.info(f\"üìã Variables li√©es √† la conversation: {conversation_vars}\")\n",
    "    \n",
    "    # Chercher des traces d'agents\n",
    "    agent_vars = [var for var in globals().keys() if 'agent' in var.lower()]\n",
    "    logger.info(f\"üë• Variables li√©es aux agents: {agent_vars}\")\n",
    "    \n",
    "    # Chercher des traces de Tweety/JVM\n",
    "    tweety_vars = [var for var in globals().keys() if 'jvm' in var.lower() or 'tweety' in var.lower() or 'java' in var.lower()]\n",
    "    logger.info(f\"‚òï Variables li√©es √† Tweety/JVM: {tweety_vars}\")\n",
    "    \n",
    "    analysis_results['global_vars_count'] = len(globals())\n",
    "    analysis_results['conversation_vars'] = conversation_vars\n",
    "    analysis_results['agent_vars'] = agent_vars\n",
    "    analysis_results['tweety_vars'] = tweety_vars\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Erreur analyse variables: {e}\")\n",
    "\n",
    "# Validation finale\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"üéØ R√âSULTATS FINAUX VALIDATION PIPELINE\")\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(f\"‚è±Ô∏è Dur√©e conversation: {conversation_duration:.2f} secondes\")\n",
    "logger.info(f\"üî¢ Variables globales cr√©√©es: {len(globals())}\")\n",
    "logger.info(f\"üìä R√©sultats d√©taill√©s: {analysis_results}\")\n",
    "\n",
    "# Validation succ√®s\n",
    "if conversation_duration > 30:  # Plus de 30 secondes = conversation substantielle\n",
    "    logger.info(\"‚úÖ SUCCESS: Conversation agentique substantielle ex√©cut√©e\")\n",
    "    pipeline_status = \"OP√âRATIONNEL\"\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è Conversation courte, v√©rifier qualit√©\")\n",
    "    pipeline_status = \"PARTIELLEMENT VALID√â\"\n",
    "\n",
    "logger.info(f\"üèÜ STATUT FINAL PIPELINE: {pipeline_status}\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "# Export des r√©sultats pour analyse\n",
    "results_summary = {\n",
    "    'pipeline_status': pipeline_status,\n",
    "    'conversation_duration': conversation_duration,\n",
    "    'analysis_results': analysis_results,\n",
    "    'validation_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "# Sauvegarder les r√©sultats\n",
    "with open('conversation_validation_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "logger.info(\"üíæ R√©sultats sauvegard√©s dans conversation_validation_results.json\")\n",
    "logger.info(\"üéâ VALIDATION PIPELINE TERMIN√âE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
